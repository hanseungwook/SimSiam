name: simclr-joint-cifar10-experiment
dataset: 
  name: cifar10
  image_size: 32
  num_workers: 4

model: 
  name: simclr_joint
  backbone: resnet18_cifar_variant1

load_model: False

train:
  optimizer: 
    name: adam
    weight_decay: 0.0
    momentum: 0.0
  # warmup_epochs: 10
  # warmup_lr: 0
  base_lr: 0.001
  # final_lr: 0
  pretrain_epochs: 1
  max_step_int: 3 # Interval in number of iterations in which to perform MI maximization step (every X steps)
  num_epochs: 800 # this parameter influence the lr decay
  stop_at_epoch: 800 # has to be smaller than num_epochs
  batch_size: 512
  knn_monitor: True # knn monitor will take more time
  knn_interval: 1
  knn_k: 200
  symmetric_loss_weight: 1.0
  logistic_loss_weight: 1.0
eval: # linear evaluation, False will turn off automatic evaluation after training
  optimizer: 
    name: sgd
    weight_decay: 0
    momentum: 0.9
  warmup_lr: 0
  warmup_epochs: 0
  base_lr: 30
  final_lr: 0
  batch_size: 256
  num_epochs: 30

logger:
  tensorboard: True
  matplotlib: True
  
seed: null # None type for yaml file
# two things might lead to stochastic behavior other than seed:
# worker_init_fn from dataloader and torch.nn.functional.interpolate 
# (keep this in mind if you want to achieve 100% deterministic)




